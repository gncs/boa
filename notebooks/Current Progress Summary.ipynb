{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Models: FFT\n",
    "\n",
    "![Old BOA](../plots/notebook_plots/model_goodness_of_fit/fft/old.png \"Old BOA\")\n",
    "![New BOA](../plots/notebook_plots/model_goodness_of_fit/fft/new.png \"New BOA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Models: Stencil3D\n",
    "\n",
    "![Old BOA](../plots/notebook_plots/model_goodness_of_fit/stencil3d/old.png \"Old BOA\")\n",
    "![New BOA](../plots/notebook_plots/model_goodness_of_fit/stencil3d/new.png \"New BOA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of Models: GEMM\n",
    "\n",
    "![New BOA](../plots/notebook_plots/model_goodness_of_fit/gemm/new.png \"New BOA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesOpt Performance: Stencil3D\n",
    "\n",
    "![New BOA](../plots/notebook_plots/bayesopt_analysis/stencil3d/bayesopt.png \"New BOA\")\n",
    "![New BOA](../plots/notebook_plots/bayesopt_analysis/stencil3d/bayesopt_comparisons.png \"New BOA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesOpt Performance: GEMM\n",
    "\n",
    "![New BOA](../plots/notebook_plots/bayesopt_analysis/gemm/bayesopt.png \"New BOA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the Ordering: Method\n",
    "\n",
    "**Perspective:** for $N$ outputs, there are $N!$ GPAR models we could choose from: **model selection**!\n",
    "\n",
    "Classic model selection framework: \n",
    "- Split data into **train**, **validation**, **test**.\n",
    "- Select select model on **validation**\n",
    "- Retrain on **train + validation**, report performance on **test** \n",
    "\n",
    "Our experimental setup:\n",
    "\n",
    "1. Split data into **train+validation** and **test**.\n",
    "2. Repeat the steps below $E$ times:\n",
    "3. Split get a **train** and **validation** split.\n",
    "4. Consider $P$ permutations.\n",
    "5. Train $P$ models, and report their performances on **validation**\n",
    "6. Pick best model, retrain on **train+validation**, report performance on **test**.\n",
    "\n",
    "Both for random and greedy search, we ran $E = 25$ experiments.\n",
    "\n",
    "- For **random** search, we sampled $P = 9$ permutations uniformly.\n",
    "- For **greedy** search, $P = \\frac{9(9 - 1)}{2} = 36$ permutations are considered (by following greedy selection).\n",
    "\n",
    "# Learning the Ordering: Hierarchical BayesOpt\n",
    "\n",
    "## Motivation\n",
    "\n",
    "**Random search**: Uniformly sample $P$ permutations, train $P$ GPAR models, select best permutation based on validation set log-likelihood.\n",
    "\n",
    "**Problem:** GPAR training expensive, sampling doesn't take into account previous observations.\n",
    "\n",
    "**Solution:** Perform BO to select the permutation!\n",
    "\n",
    "## Details\n",
    "\n",
    "**To perform BO, we need a kernel over permutations.**\n",
    "\n",
    "**Idea:** Modify the EQ kernel appropriately.\n",
    "\n",
    "EQ kernel:\n",
    "\n",
    "$$\n",
    "    k(x, y) = \\alpha^2 \\exp\\left\\{\\frac{||x - y||^2}{L}\\right\\}\n",
    "$$\n",
    "\n",
    "Assume $x, y \\in \\mathbb{R}^N$, and $x, y \\sim \\mathcal{N}(0, I)$. Then\n",
    "\n",
    "$$\n",
    "    \\mathbb{E}||x - y||^2 = 2N (1 - \\text{Corr}[x, y]),\n",
    "$$\n",
    "where $\\text{Corr}[x, y]$ is the Pearson correlation.\n",
    "\n",
    "Kendall $\\tau$: Correlation coefficient between two permutations $\\pi$ and $\\rho$ over $N$ items:\n",
    "$$\n",
    "    \\tau(\\pi, \\rho) = 1 - \\frac{2d(\\pi, \\rho)}{N(N - 1)}\n",
    "$$\n",
    "\n",
    "Perform replacement:\n",
    "$$\n",
    "    k(x, y) = \\alpha^2 \\exp\\left\\{\\frac{||x - y||^2}{L}\\right\\} \\quad\\to\\quad\n",
    "    k'(\\pi, \\rho) = \\alpha^2 \\exp\\left\\{\\frac{2N (1 - \\tau(\\pi, \\rho))}{L}\\right\\} = \\alpha^2 \\exp\\left\\{\\frac{2d(\\pi, \\rho)}{L(N - 1)}\\right\\}\n",
    "$$\n",
    "\n",
    "**Note:** $k'(\\pi, \\rho)$ is clearly a valid kernel!\n",
    "\n",
    "This is a single-output problem: Use **Expected Improvement** as our acquisition function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning the Ordering: Baselines on Stencil3D\n",
    "\n",
    "![New BOA](../plots/notebook_plots/ordering/stencil3d/random_vs_greedy.png?3 \"New BOA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
